# Robots.txt

By default, the robots.txt allows all robots to crawl the website. It's possible to modify the robots.txt file in the `app.config.ts` file.

For example if you don't want to block yandex:
```typescript
    robots: [
    {
        UserAgent: "Yandex",
        Disallow: ["/"],
    },
],
```

The default configuration allows all robots to crawl the website.

::alert
Don't forget to configure URL with the url of your website at the top of the app.config.ts file.
::
